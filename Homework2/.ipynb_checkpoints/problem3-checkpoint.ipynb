{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import torch\n",
    "#print(torch.__version__)\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "import torch.nn.init\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>V</th>\n",
       "      <th>M</th>\n",
       "      <th>n</th>\n",
       "      <th>np</th>\n",
       "      <th>B</th>\n",
       "      <th>G</th>\n",
       "      <th>E</th>\n",
       "      <th>v</th>\n",
       "      <th>H</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 43</th>\n",
       "      <th>Unnamed: 44</th>\n",
       "      <th>Unnamed: 45</th>\n",
       "      <th>Unnamed: 46</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "      <th>Unnamed: 48</th>\n",
       "      <th>Unnamed: 49</th>\n",
       "      <th>Unnamed: 50</th>\n",
       "      <th>Unnamed: 51</th>\n",
       "      <th>Unnamed: 52</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66_C</td>\n",
       "      <td>11.41</td>\n",
       "      <td>24.022</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>431.7450</td>\n",
       "      <td>518.2490</td>\n",
       "      <td>1110.438653</td>\n",
       "      <td>0.071337</td>\n",
       "      <td>95.902307</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20012_InSb</td>\n",
       "      <td>73.73</td>\n",
       "      <td>236.570</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>36.8242</td>\n",
       "      <td>14.5179</td>\n",
       "      <td>38.494849</td>\n",
       "      <td>0.325772</td>\n",
       "      <td>3.219550</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1190_ZnSe</td>\n",
       "      <td>47.34</td>\n",
       "      <td>144.350</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>56.3189</td>\n",
       "      <td>29.0179</td>\n",
       "      <td>74.293904</td>\n",
       "      <td>0.280139</td>\n",
       "      <td>6.603032</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>682_NaF</td>\n",
       "      <td>24.74</td>\n",
       "      <td>41.988</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>52.4118</td>\n",
       "      <td>36.3275</td>\n",
       "      <td>88.528881</td>\n",
       "      <td>0.218483</td>\n",
       "      <td>10.653966</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16220_Si</td>\n",
       "      <td>40.97</td>\n",
       "      <td>56.170</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>90.0009</td>\n",
       "      <td>63.4097</td>\n",
       "      <td>154.050571</td>\n",
       "      <td>0.214724</td>\n",
       "      <td>15.043345</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name      V        M  n  np         B         G            E  \\\n",
       "0        66_C  11.41   24.022  2   2  431.7450  518.2490  1110.438653   \n",
       "1  20012_InSb  73.73  236.570  2   2   36.8242   14.5179    38.494849   \n",
       "2   1190_ZnSe  47.34  144.350  2   2   56.3189   29.0179    74.293904   \n",
       "3     682_NaF  24.74   41.988  2   2   52.4118   36.3275    88.528881   \n",
       "4    16220_Si  40.97   56.170  2   2   90.0009   63.4097   154.050571   \n",
       "\n",
       "          v          H  ...  Unnamed: 43  Unnamed: 44  Unnamed: 45  \\\n",
       "0  0.071337  95.902307  ...          NaN          NaN          NaN   \n",
       "1  0.325772   3.219550  ...          NaN          NaN          NaN   \n",
       "2  0.280139   6.603032  ...          NaN          NaN          NaN   \n",
       "3  0.218483  10.653966  ...          NaN          NaN          NaN   \n",
       "4  0.214724  15.043345  ...          NaN          NaN          NaN   \n",
       "\n",
       "   Unnamed: 46  Unnamed: 47  Unnamed: 48  Unnamed: 49  Unnamed: 50  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "1          NaN          NaN          NaN          NaN          NaN   \n",
       "2          NaN          NaN          NaN          NaN          NaN   \n",
       "3          NaN          NaN          NaN          NaN          NaN   \n",
       "4          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   Unnamed: 51  Unnamed: 52  \n",
       "0          NaN          NaN  \n",
       "1          NaN          NaN  \n",
       "2          NaN          NaN  \n",
       "3          NaN          NaN  \n",
       "4          NaN          NaN  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 1107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('thermal-dataset.xlsx', sheet_name ='dataset')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'V', 'M', 'n', 'np', 'B', 'G', 'E', 'v', 'H', 'B'', 'G'', 'ρ',\n",
       "       'vL', 'vS', 'va', 'Θe', 'γel', 'γes', 'γe', 'A', 'y-exp', 'y-theory',\n",
       "       'Formula', 'space group', 'k_BTE_DFT', 'k_BTE_DFT（1000 K）',\n",
       "       'k_AFLOW_AAPL', 'k_AFLOW_AGL', 'k_AFLOW_AGL (Poisson ratio σ=0.25)',\n",
       "       'k_Mingo', 'k_EXP', 'k_EXP（1000 K）', 'Unnamed: 33', 'Unnamed: 34',\n",
       "       'Unnamed: 35', 'Unnamed: 36', 'Unnamed: 37', 'Unnamed: 38',\n",
       "       'Unnamed: 39', 'Unnamed: 40', 'Unnamed: 41', 'Unnamed: 42',\n",
       "       'Unnamed: 43', 'Unnamed: 44', 'Unnamed: 45', 'Unnamed: 46',\n",
       "       'Unnamed: 47', 'Unnamed: 48', 'Unnamed: 49', 'Unnamed: 50',\n",
       "       'Unnamed: 51', 'Unnamed: 52'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'V', 'M', 'n', 'np', 'B', 'G', 'E', 'v', 'H', 'B'', 'G'', 'ρ',\n",
       "       'vL', 'vS', 'va', 'Θe', 'γel', 'γes', 'γe', 'A', 'y-exp', 'y-theory'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.loc[:, :'y-theory']\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V</th>\n",
       "      <th>M</th>\n",
       "      <th>n</th>\n",
       "      <th>np</th>\n",
       "      <th>B</th>\n",
       "      <th>G</th>\n",
       "      <th>E</th>\n",
       "      <th>v</th>\n",
       "      <th>H</th>\n",
       "      <th>B'</th>\n",
       "      <th>...</th>\n",
       "      <th>vL</th>\n",
       "      <th>vS</th>\n",
       "      <th>va</th>\n",
       "      <th>Θe</th>\n",
       "      <th>γel</th>\n",
       "      <th>γes</th>\n",
       "      <th>γe</th>\n",
       "      <th>A</th>\n",
       "      <th>y-exp</th>\n",
       "      <th>y-theory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>370.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>3.700000e+02</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>370.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>145.503405</td>\n",
       "      <td>576.941738</td>\n",
       "      <td>6.810811</td>\n",
       "      <td>3.789189</td>\n",
       "      <td>111.257870</td>\n",
       "      <td>59.678087</td>\n",
       "      <td>147.105572</td>\n",
       "      <td>0.296581</td>\n",
       "      <td>10.521358</td>\n",
       "      <td>-6.982807</td>\n",
       "      <td>...</td>\n",
       "      <td>5.385817</td>\n",
       "      <td>2.928926</td>\n",
       "      <td>3.256445</td>\n",
       "      <td>263.253037</td>\n",
       "      <td>1.594866</td>\n",
       "      <td>1.119608</td>\n",
       "      <td>1.995672</td>\n",
       "      <td>9.121067e-05</td>\n",
       "      <td>44.079546</td>\n",
       "      <td>24.255426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>132.334810</td>\n",
       "      <td>625.505406</td>\n",
       "      <td>4.818313</td>\n",
       "      <td>3.150066</td>\n",
       "      <td>82.433063</td>\n",
       "      <td>77.165080</td>\n",
       "      <td>170.936177</td>\n",
       "      <td>0.083493</td>\n",
       "      <td>14.299973</td>\n",
       "      <td>11.632497</td>\n",
       "      <td>...</td>\n",
       "      <td>2.784979</td>\n",
       "      <td>1.973751</td>\n",
       "      <td>2.152686</td>\n",
       "      <td>225.042124</td>\n",
       "      <td>2.868737</td>\n",
       "      <td>4.816583</td>\n",
       "      <td>3.987999</td>\n",
       "      <td>9.802296e-04</td>\n",
       "      <td>277.377084</td>\n",
       "      <td>49.038768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.410000</td>\n",
       "      <td>8.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.904080</td>\n",
       "      <td>0.406580</td>\n",
       "      <td>1.215183</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.006197</td>\n",
       "      <td>-104.589000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.559351</td>\n",
       "      <td>0.331246</td>\n",
       "      <td>0.379108</td>\n",
       "      <td>25.916963</td>\n",
       "      <td>-7.029521</td>\n",
       "      <td>-65.475244</td>\n",
       "      <td>0.414990</td>\n",
       "      <td>1.459528e-07</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>0.026157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>53.210000</td>\n",
       "      <td>157.831500</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>47.720850</td>\n",
       "      <td>19.017575</td>\n",
       "      <td>49.639698</td>\n",
       "      <td>0.250683</td>\n",
       "      <td>3.580389</td>\n",
       "      <td>-8.717083</td>\n",
       "      <td>...</td>\n",
       "      <td>3.836785</td>\n",
       "      <td>1.889592</td>\n",
       "      <td>2.115443</td>\n",
       "      <td>144.201287</td>\n",
       "      <td>1.107011</td>\n",
       "      <td>0.624775</td>\n",
       "      <td>0.921418</td>\n",
       "      <td>9.899596e-07</td>\n",
       "      <td>3.887500</td>\n",
       "      <td>4.432038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76.590000</td>\n",
       "      <td>287.557000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>92.003700</td>\n",
       "      <td>44.813700</td>\n",
       "      <td>114.970283</td>\n",
       "      <td>0.303591</td>\n",
       "      <td>7.326539</td>\n",
       "      <td>-2.906780</td>\n",
       "      <td>...</td>\n",
       "      <td>4.836986</td>\n",
       "      <td>2.496888</td>\n",
       "      <td>2.782292</td>\n",
       "      <td>210.531759</td>\n",
       "      <td>1.379069</td>\n",
       "      <td>1.027563</td>\n",
       "      <td>1.199428</td>\n",
       "      <td>1.864054e-06</td>\n",
       "      <td>11.075000</td>\n",
       "      <td>12.781238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>219.020000</td>\n",
       "      <td>907.187000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>160.493000</td>\n",
       "      <td>67.233975</td>\n",
       "      <td>175.339469</td>\n",
       "      <td>0.344524</td>\n",
       "      <td>11.691259</td>\n",
       "      <td>-1.296300</td>\n",
       "      <td>...</td>\n",
       "      <td>5.826099</td>\n",
       "      <td>3.203630</td>\n",
       "      <td>3.595112</td>\n",
       "      <td>281.975073</td>\n",
       "      <td>1.606329</td>\n",
       "      <td>1.373321</td>\n",
       "      <td>1.597086</td>\n",
       "      <td>3.706014e-06</td>\n",
       "      <td>23.082500</td>\n",
       "      <td>22.402090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>995.000000</td>\n",
       "      <td>5168.290000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>434.165000</td>\n",
       "      <td>523.852000</td>\n",
       "      <td>1120.785827</td>\n",
       "      <td>0.494396</td>\n",
       "      <td>106.084131</td>\n",
       "      <td>29.742400</td>\n",
       "      <td>...</td>\n",
       "      <td>18.019141</td>\n",
       "      <td>12.254442</td>\n",
       "      <td>13.361204</td>\n",
       "      <td>1755.800206</td>\n",
       "      <td>51.169090</td>\n",
       "      <td>47.244050</td>\n",
       "      <td>53.566903</td>\n",
       "      <td>1.670399e-02</td>\n",
       "      <td>5200.000000</td>\n",
       "      <td>547.103092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                V            M           n          np           B  \\\n",
       "count  370.000000   370.000000  370.000000  370.000000  370.000000   \n",
       "mean   145.503405   576.941738    6.810811    3.789189  111.257870   \n",
       "std    132.334810   625.505406    4.818313    3.150066   82.433063   \n",
       "min     11.410000     8.010000    2.000000    2.000000    7.904080   \n",
       "25%     53.210000   157.831500    3.000000    3.000000   47.720850   \n",
       "50%     76.590000   287.557000    5.000000    3.000000   92.003700   \n",
       "75%    219.020000   907.187000   12.000000    3.000000  160.493000   \n",
       "max    995.000000  5168.290000   29.000000   29.000000  434.165000   \n",
       "\n",
       "                G            E           v           H          B'  ...  \\\n",
       "count  370.000000   370.000000  370.000000  370.000000  370.000000  ...   \n",
       "mean    59.678087   147.105572    0.296581   10.521358   -6.982807  ...   \n",
       "std     77.165080   170.936177    0.083493   14.299973   11.632497  ...   \n",
       "min      0.406580     1.215183    0.000656    0.006197 -104.589000  ...   \n",
       "25%     19.017575    49.639698    0.250683    3.580389   -8.717083  ...   \n",
       "50%     44.813700   114.970283    0.303591    7.326539   -2.906780  ...   \n",
       "75%     67.233975   175.339469    0.344524   11.691259   -1.296300  ...   \n",
       "max    523.852000  1120.785827    0.494396  106.084131   29.742400  ...   \n",
       "\n",
       "               vL          vS          va           Θe         γel  \\\n",
       "count  370.000000  370.000000  370.000000   370.000000  370.000000   \n",
       "mean     5.385817    2.928926    3.256445   263.253037    1.594866   \n",
       "std      2.784979    1.973751    2.152686   225.042124    2.868737   \n",
       "min      1.559351    0.331246    0.379108    25.916963   -7.029521   \n",
       "25%      3.836785    1.889592    2.115443   144.201287    1.107011   \n",
       "50%      4.836986    2.496888    2.782292   210.531759    1.379069   \n",
       "75%      5.826099    3.203630    3.595112   281.975073    1.606329   \n",
       "max     18.019141   12.254442   13.361204  1755.800206   51.169090   \n",
       "\n",
       "              γes          γe             A        y-exp    y-theory  \n",
       "count  370.000000  370.000000  3.700000e+02   370.000000  370.000000  \n",
       "mean     1.119608    1.995672  9.121067e-05    44.079546   24.255426  \n",
       "std      4.816583    3.987999  9.802296e-04   277.377084   49.038768  \n",
       "min    -65.475244    0.414990  1.459528e-07     0.086000    0.026157  \n",
       "25%      0.624775    0.921418  9.899596e-07     3.887500    4.432038  \n",
       "50%      1.027563    1.199428  1.864054e-06    11.075000   12.781238  \n",
       "75%      1.373321    1.597086  3.706014e-06    23.082500   22.402090  \n",
       "max     47.244050   53.566903  1.670399e-02  5200.000000  547.103092  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 1110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(370, 23)"
      ]
     },
     "execution_count": 1111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name        0\n",
       "V           0\n",
       "M           0\n",
       "n           0\n",
       "np          0\n",
       "B           0\n",
       "G           0\n",
       "E           0\n",
       "v           0\n",
       "H           0\n",
       "B'          0\n",
       "G'          0\n",
       "ρ           0\n",
       "vL          0\n",
       "vS          0\n",
       "va          0\n",
       "Θe          0\n",
       "γel         0\n",
       "γes         0\n",
       "γe          0\n",
       "A           0\n",
       "y-exp       0\n",
       "y-theory    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name        0\n",
       "V           0\n",
       "M           0\n",
       "n           0\n",
       "np          0\n",
       "B           0\n",
       "G           0\n",
       "E           0\n",
       "v           0\n",
       "H           0\n",
       "B'          0\n",
       "G'          0\n",
       "ρ           0\n",
       "vL          0\n",
       "vS          0\n",
       "va          0\n",
       "Θe          0\n",
       "γel         0\n",
       "γes         0\n",
       "γe          0\n",
       "A           0\n",
       "y-exp       0\n",
       "y-theory    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(df.n.unique()))\n",
    "print(len(df.np.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omee/anaconda3/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "/home/omee/anaconda3/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "#Replacing \"n\"\n",
    "X = df.loc[:, ['n']]\n",
    "y = df['y-exp']\n",
    "OHEncoder = ce.OneHotEncoder(cols = ['n'])\n",
    "newCols = OHEncoder.fit_transform(X, y)\n",
    "df = df.drop(['n'], axis = 1)\n",
    "df = df.join(newCols)\n",
    "\n",
    "#Replacing \"np\"\n",
    "X = df.loc[:, ['np']]\n",
    "y = df['y-exp']\n",
    "OHEncoder = ce.OneHotEncoder(cols = ['np'])\n",
    "newCols = OHEncoder.fit_transform(X, y)\n",
    "df = df.drop(['np'], axis = 1)\n",
    "df = df.join(newCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Name', 'V', 'M', 'B', 'G', 'E', 'v', 'H', 'B'', 'G'', 'ρ', 'vL', 'vS',\n",
       "        'va', 'Θe', 'γel', 'γes', 'γe', 'A', 'y-exp', 'y-theory', 'n_1', 'n_2',\n",
       "        'n_3', 'n_4', 'n_5', 'n_6', 'n_7', 'n_8', 'n_9', 'n_10', 'n_11', 'n_12',\n",
       "        'n_13', 'n_14', 'n_15', 'np_1', 'np_2', 'np_3', 'np_4', 'np_5', 'np_6',\n",
       "        'np_7', 'np_8', 'np_9', 'np_10', 'np_11', 'np_12', 'np_13', 'np_14',\n",
       "        'np_15'],\n",
       "       dtype='object'),\n",
       " (51,))"
      ]
     },
     "execution_count": 1116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns, df.columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.47103092e+02, 4.34409393e+00, 8.83552653e+00, 1.76556363e+01,\n",
       "       4.08157516e+01, 3.04336639e+01, 1.16520522e+01, 4.06207592e+01,\n",
       "       6.14393581e+01, 1.46431122e+02, 1.30123539e+02, 4.01184072e+01,\n",
       "       3.43295845e+02, 2.66374859e+01, 2.05159539e+01, 2.65594241e+02,\n",
       "       2.22351199e+02, 2.31233787e+02, 1.92571258e+01, 1.79763713e+02,\n",
       "       1.67790030e+02, 1.78481073e+02, 1.40004820e+02, 2.24286312e+01,\n",
       "       1.71740875e+02, 1.64527923e+02, 1.51845435e+02, 1.67923922e+02,\n",
       "       2.37071428e+01, 1.66205902e+02, 2.03897001e+02, 1.92243680e+02,\n",
       "       2.49756459e+01, 1.72200844e+01, 1.87350480e+01, 1.16504218e+01,\n",
       "       2.54374342e+01, 2.02139390e+01, 2.24774423e+01, 1.20080075e+02,\n",
       "       2.47966820e+01, 8.79382272e+01, 3.49949208e+01, 1.09468699e+01,\n",
       "       1.25784369e-01, 2.20510643e+01, 3.12421349e+00, 1.97465160e+01,\n",
       "       1.90527938e+01, 1.91718068e+00, 2.39450091e+01, 9.73866313e+00,\n",
       "       3.03845914e+01, 3.20414393e+01, 3.89541097e+01, 8.96149223e+00,\n",
       "       2.85669570e+01, 6.65112711e+00, 3.40508285e+01, 3.05842531e+01,\n",
       "       3.39689710e+01, 2.05507017e-01, 2.23224679e+01, 2.45587087e+01,\n",
       "       8.29762935e+00, 7.36260300e+00, 2.80103698e+01, 3.16154980e+01,\n",
       "       2.15320886e+01, 2.26420780e+01, 2.63177523e+01, 4.67571703e+01,\n",
       "       4.30773755e+01, 6.09533909e+00, 8.65046547e+00, 2.34004053e+00,\n",
       "       7.75149142e+01, 5.47665407e+00, 3.53242012e+01, 3.94416000e+01,\n",
       "       1.20021433e+01, 5.08914221e+01, 1.69083294e+01, 7.21352016e+01,\n",
       "       3.14119588e+01, 1.27273819e+01, 1.51709553e+01, 3.28223207e+00,\n",
       "       2.02674189e+01, 3.30495737e+01, 2.90791084e+01, 1.83373582e+01,\n",
       "       3.96377487e+01, 1.18991829e+01, 1.75072170e+01, 3.27093480e+01,\n",
       "       1.71017892e+01, 1.13501037e+01, 2.30483093e+01, 1.77691891e+01,\n",
       "       2.19234709e+01, 3.41787100e+01, 2.27959070e+01, 1.63564010e+01,\n",
       "       2.16242032e+01, 2.00398992e+01, 2.27976789e+01, 1.37785223e+01,\n",
       "       2.75007793e+01, 1.99154628e+01, 2.47836148e+01, 1.73359633e+01,\n",
       "       3.77560599e+01, 3.32603395e+01, 9.43594512e+00, 1.84773780e+00,\n",
       "       1.88979225e+01, 7.90670048e+00, 1.69760930e+01, 9.18546172e+00,\n",
       "       4.08150166e+00, 7.06583292e+00, 1.65520539e+01, 2.38350165e+01,\n",
       "       2.57434287e+01, 2.00693898e+01, 1.70128236e+01, 1.61522492e+01,\n",
       "       1.88784441e+01, 2.72757751e+01, 1.66588056e+01, 1.74104882e+01,\n",
       "       1.59328786e+00, 1.95905369e+01, 1.79561618e+01, 2.10138204e+01,\n",
       "       6.72197104e+00, 3.26447628e+00, 1.82650146e+01, 2.34998389e+01,\n",
       "       2.16200609e+01, 1.44831472e+01, 1.33251499e+01, 2.80280149e+01,\n",
       "       1.61728870e+01, 3.04090316e+01, 1.62718422e+01, 1.51427223e+01,\n",
       "       1.12671499e+01, 2.14837982e+01, 3.78711938e+00, 1.71447893e+01,\n",
       "       1.04541827e+01, 6.93137464e-01, 6.85182043e+00, 3.06271582e+01,\n",
       "       1.57261540e+01, 1.64410479e+01, 2.01587368e+01, 1.33061087e+01,\n",
       "       1.88206552e+01, 5.79313705e+00, 2.25597395e+01, 4.24975766e+00,\n",
       "       2.83164783e+01, 1.53083268e+01, 1.15711100e+01, 2.14553190e+01,\n",
       "       1.74982841e+01, 1.55779971e+01, 2.35028412e+01, 1.29251645e+01,\n",
       "       1.64479824e+01, 2.85773772e+01, 1.39327147e+01, 1.35916819e+01,\n",
       "       2.15628345e+01, 3.05988048e+00, 1.48873844e+01, 3.21075227e+01,\n",
       "       1.43648492e+01, 2.30096056e+01, 1.84231554e+01, 2.05799561e+01,\n",
       "       1.19368553e+01, 1.43817415e+01, 3.57024924e+01, 5.21122737e+00,\n",
       "       4.32578101e+00, 5.58205288e+00, 2.17260629e+01, 1.01060723e+01,\n",
       "       5.75620721e+01, 1.32101550e+01, 9.83807090e+00, 2.37039997e+01,\n",
       "       4.68488544e+00, 2.60621562e+01, 1.27955307e+01, 9.87549460e+00,\n",
       "       7.49914674e+00, 1.39262986e+01, 1.74999981e+01, 1.43782552e+01,\n",
       "       5.20508520e+00, 8.88288366e+01, 4.37138446e+00, 2.95175539e+01,\n",
       "       7.02043759e+00, 9.73786277e+00, 1.67708733e+01, 9.74149792e-01,\n",
       "       1.95772805e+00, 2.78070601e+01, 3.53020193e+00, 1.13174313e+00,\n",
       "       2.21542397e+01, 1.31589185e+01, 1.26880042e+01, 2.25377429e+01,\n",
       "       2.07157375e+01, 3.69932145e+00, 1.76982382e+01, 1.48879151e+01,\n",
       "       1.41986224e+01, 2.61569259e-02, 1.00518692e+01, 1.05390989e+01,\n",
       "       3.29004360e+00, 1.28611323e+01, 7.23314103e+00, 4.50115231e+00,\n",
       "       3.00425481e+01, 8.94813453e+00, 3.61395081e+00, 6.15020170e+00,\n",
       "       1.95089564e+00, 1.75907381e+01, 3.02375834e+00, 3.95161943e+00,\n",
       "       1.62754419e+00, 3.96588971e+01, 1.28553912e+01, 2.11576445e+01,\n",
       "       1.05819956e+01, 5.43561186e+00, 6.55970550e+00, 3.29203773e+00,\n",
       "       1.59976574e+00, 1.80076513e+01, 3.02465067e+01, 1.34754760e+01,\n",
       "       4.56557464e+00, 7.09127007e+00, 1.96484112e+01, 5.39837312e+00,\n",
       "       9.50048390e+00, 1.81240545e+00, 6.17561643e+00, 7.01861804e+00,\n",
       "       5.29068353e+00, 2.41394394e+01, 2.05044185e+01, 3.33663123e+00,\n",
       "       7.62600521e+00, 1.23968055e+01, 5.68709847e+00, 1.31685828e+01,\n",
       "       7.70719278e+00, 4.65233947e+00, 4.88642760e+00, 5.17864922e+00,\n",
       "       6.26743790e-01, 8.21621408e+00, 1.43762124e+00, 4.24121070e+01,\n",
       "       9.59804261e+00, 2.18554701e+00, 2.38326378e+00, 1.74247346e+01,\n",
       "       3.04777912e+00, 1.22762446e+01, 3.68372851e+01, 8.10915946e+00,\n",
       "       1.18216929e+01, 3.92364798e+00, 9.46611215e+00, 3.26456748e+00,\n",
       "       7.03684942e-01, 1.10425509e+01, 7.90091851e+00, 1.19473279e+00,\n",
       "       6.85958280e+00, 3.78439485e+00, 1.27669448e+01, 3.25673800e+00,\n",
       "       2.62369831e+00, 1.35099485e+00, 1.16857362e+01, 7.93100912e+00,\n",
       "       3.11997448e+00, 7.56870471e-01, 4.36058846e+00, 3.09555325e+00,\n",
       "       1.96140873e+00, 3.46864117e+00, 4.92492235e-01, 8.36625635e+00,\n",
       "       1.93207700e+00, 9.74037753e+00, 2.89308690e+00, 1.03206281e+01,\n",
       "       6.87593537e+00, 1.43715298e+00, 7.89477442e+00, 6.30302415e+00,\n",
       "       1.59047843e+00, 3.81511016e+00, 1.68936933e+00, 1.54770536e+00,\n",
       "       1.10451988e+01, 9.05841890e+00, 8.54414730e+00, 3.07084806e+00,\n",
       "       6.02769170e+00, 2.26279898e+00, 1.07287924e+01, 1.45271856e+01,\n",
       "       4.32299292e-01, 2.55593828e+00, 1.91698568e+00, 2.49120440e+00,\n",
       "       1.32372237e+00, 2.92061388e+00, 6.55310223e+00, 2.51040062e+00,\n",
       "       6.94059003e+00, 5.38312696e+00, 1.62809413e+00, 2.04605824e+00,\n",
       "       2.00516012e+00, 1.26884651e+01, 4.81842258e+00, 5.41489760e+00,\n",
       "       1.36174036e+01, 2.75354892e+00, 2.51516109e+00, 1.60706585e+01,\n",
       "       8.55302941e-01, 4.40900036e+00, 6.20943773e+00, 1.82305786e+00,\n",
       "       2.71002748e+00, 2.54574190e+00, 7.62803305e-01, 1.34200585e+01,\n",
       "       1.59646311e+00, 1.05519943e+01, 1.49621502e+00, 7.92304811e-01,\n",
       "       1.71585188e+00, 2.52008552e-01, 9.20056249e-01, 1.06439966e+00,\n",
       "       1.50476311e+00, 3.55214587e-01, 2.92956897e-01, 4.72718721e-01,\n",
       "       9.19026080e-01, 9.01755135e-01])"
      ]
     },
     "execution_count": 1117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_theory = df['y-theory'].values\n",
    "df = df.drop(columns=['y-theory'])\n",
    "y_theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.25, random_state=42, shuffle=True)\n",
    "test, val = train_test_split(test, test_size=0.4, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49,\n",
       " array(['V', 'M', 'B', 'G', 'E', 'v', 'H', \"B'\", \"G'\", 'ρ', 'vL', 'vS',\n",
       "        'va', 'Θe', 'γel', 'γes', 'γe', 'A', 'y-exp', 'n_1', 'n_2', 'n_3',\n",
       "        'n_4', 'n_5', 'n_6', 'n_7', 'n_8', 'n_9', 'n_10', 'n_11', 'n_12',\n",
       "        'n_13', 'n_14', 'n_15', 'np_1', 'np_2', 'np_3', 'np_4', 'np_5',\n",
       "        'np_6', 'np_7', 'np_8', 'np_9', 'np_10', 'np_11', 'np_12', 'np_13',\n",
       "        'np_14', 'np_15'], dtype=object))"
      ]
     },
     "execution_count": 1120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train['y-exp'].values\n",
    "excluded_columns = [\"Name\"]\n",
    "X_train = train.drop(excluded_columns, axis=1)\n",
    "\n",
    "y_test = test['y-exp'].values\n",
    "excluded_columns = [\"Name\"]\n",
    "X_test = test.drop(excluded_columns, axis=1)\n",
    "\n",
    "y_val = test['y-exp'].values\n",
    "excluded_columns = [\"Name\"]\n",
    "X_val = test.drop(excluded_columns, axis=1)\n",
    "\n",
    "X_train.shape[1], X_train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((277, 49), (55,), (55, 49), (55,))"
      ]
     },
     "execution_count": 1121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_test.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1122,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([277, 1]), torch.Size([55, 1]))"
      ]
     },
     "execution_count": 1123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = torch.from_numpy(y_train)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "y_val = torch.from_numpy(y_val)\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "y_val = y_val.view(y_val.shape[0], 1)\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([277, 49]), torch.Size([55, 49]))"
      ]
     },
     "execution_count": 1124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.from_numpy(X_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "X_val = torch.from_numpy(X_val)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([277, 49]),\n",
       " torch.Size([55, 49]),\n",
       " torch.Size([277, 1]),\n",
       " torch.Size([55, 1]))"
      ]
     },
     "execution_count": 1125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = Variable(X_train).to(device)\n",
    "X_test = Variable(X_test).to(device)\n",
    "X_val = Variable(X_val).to(device)\n",
    "y_train = Variable(y_train).to(device)\n",
    "y_test = Variable(y_test).to(device)\n",
    "y_val = Variable(y_val).to(device)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IRNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IRNet, self).__init__()\n",
    "        \n",
    "        self.linearXto1024 = nn.Sequential(\n",
    "            nn.Linear(X_train.shape[1], 1024, bias=True),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.linear1024to1024 = nn.Sequential(\n",
    "            nn.Linear(1024, 1024, bias=True),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.linear1024to512 = nn.Sequential(\n",
    "            nn.Linear(1024, 512, bias=True),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.linear512to512 = nn.Sequential(\n",
    "            nn.Linear(512, 512, bias=True),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.linear512to256 = nn.Sequential(\n",
    "            nn.Linear(512, 256, bias=True),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.linear256to256 = nn.Sequential(\n",
    "            nn.Linear(256, 256, bias=True),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.linear256to128 = nn.Sequential(\n",
    "            nn.Linear(256, 128, bias=True),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.linear128to128 = nn.Sequential(\n",
    "            nn.Linear(128, 128, bias=True),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.linear128to64 = nn.Sequential(\n",
    "            nn.Linear(128, 64, bias=True),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.linear64to64 = nn.Sequential(\n",
    "            nn.Linear(64, 64, bias=True),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.linear64to32 = nn.Sequential(\n",
    "            nn.Linear(64, 32, bias=True),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.linear32to32 = nn.Sequential(\n",
    "            nn.Linear(32, 32, bias=True),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.linear32to1 = nn.Linear(32, 1, bias=True)\n",
    "        \n",
    "        self.projectionXto1024 = nn.Linear(X_train.shape[1], 1024, bias=True)\n",
    "        self.projection1024to512 = nn.Linear(1024, 512, bias=True)\n",
    "        self.projection512to256 = nn.Linear(512, 256, bias=True)\n",
    "        self.projection256to128 = nn.Linear(256, 128, bias=True)\n",
    "        self.projection128to64 = nn.Linear(128, 64, bias=True)\n",
    "        self.projection64to32 = nn.Linear(64, 32, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outPrev = x\n",
    "        \n",
    "        out = self.linearXto1024(x)\n",
    "        out = torch.add(out, self.projectionXto1024(outPrev))\n",
    "        outPrev = out\n",
    "        \n",
    "        out = self.linear1024to1024(out)\n",
    "        out = torch.add(out, outPrev)\n",
    "        outPrev = out\n",
    "        out = self.linear1024to1024(out)\n",
    "        out = torch.add(out, outPrev)\n",
    "        outPrev = out\n",
    "        out = self.linear1024to1024(out)\n",
    "        out = torch.add(out, outPrev)\n",
    "        outPrev = out\n",
    "        \n",
    "        out = self.linear1024to512(out)\n",
    "        out = torch.add(out, self.projection1024to512(outPrev))\n",
    "        outPrev = out\n",
    "        \n",
    "        out = self.linear512to512(out)\n",
    "        out = torch.add(out, outPrev)\n",
    "        outPrev = out\n",
    "        out = self.linear512to512(out)\n",
    "        out = torch.add(out, outPrev)\n",
    "        outPrev = out\n",
    "        \n",
    "        out = self.linear512to256(out)\n",
    "        out = torch.add(out, self.projection512to256(outPrev))\n",
    "        outPrev = out\n",
    "        \n",
    "        out = self.linear256to256(out)\n",
    "        out = torch.add(out, outPrev)\n",
    "        outPrev = out\n",
    "        out = self.linear256to256(out)\n",
    "        out = torch.add(out, outPrev)\n",
    "        outPrev = out\n",
    "        \n",
    "        out = self.linear256to128(out)\n",
    "        out = torch.add(out, self.projection256to128(outPrev))\n",
    "        outPrev = out\n",
    "        \n",
    "        out = self.linear128to128(out)\n",
    "        out = torch.add(out, outPrev)\n",
    "        outPrev = out\n",
    "        out = self.linear128to128(out)\n",
    "        out = torch.add(out, outPrev)\n",
    "        outPrev = out\n",
    "        \n",
    "        out = self.linear128to64(out)\n",
    "        out = torch.add(out, self.projection128to64(outPrev))\n",
    "        outPrev = out\n",
    "        \n",
    "        out = self.linear64to64(out)\n",
    "        out = torch.add(out, outPrev)\n",
    "        outPrev = out\n",
    "        \n",
    "        out = self.linear64to32(out)\n",
    "        out = torch.add(out, self.projection64to32(outPrev))\n",
    "        \n",
    "        out = self.linear32to1(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "irnet = IRNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linearXto1024.0.weight torch.Size([1024, 49])\n",
      "linearXto1024.0.bias torch.Size([1024])\n",
      "linearXto1024.1.weight torch.Size([1024])\n",
      "linearXto1024.1.bias torch.Size([1024])\n",
      "linearXto1024.1.running_mean torch.Size([1024])\n",
      "linearXto1024.1.running_var torch.Size([1024])\n",
      "linearXto1024.1.num_batches_tracked torch.Size([])\n",
      "linear1024to1024.0.weight torch.Size([1024, 1024])\n",
      "linear1024to1024.0.bias torch.Size([1024])\n",
      "linear1024to1024.1.weight torch.Size([1024])\n",
      "linear1024to1024.1.bias torch.Size([1024])\n",
      "linear1024to1024.1.running_mean torch.Size([1024])\n",
      "linear1024to1024.1.running_var torch.Size([1024])\n",
      "linear1024to1024.1.num_batches_tracked torch.Size([])\n",
      "linear1024to512.0.weight torch.Size([512, 1024])\n",
      "linear1024to512.0.bias torch.Size([512])\n",
      "linear1024to512.1.weight torch.Size([512])\n",
      "linear1024to512.1.bias torch.Size([512])\n",
      "linear1024to512.1.running_mean torch.Size([512])\n",
      "linear1024to512.1.running_var torch.Size([512])\n",
      "linear1024to512.1.num_batches_tracked torch.Size([])\n",
      "linear512to512.0.weight torch.Size([512, 512])\n",
      "linear512to512.0.bias torch.Size([512])\n",
      "linear512to512.1.weight torch.Size([512])\n",
      "linear512to512.1.bias torch.Size([512])\n",
      "linear512to512.1.running_mean torch.Size([512])\n",
      "linear512to512.1.running_var torch.Size([512])\n",
      "linear512to512.1.num_batches_tracked torch.Size([])\n",
      "linear512to256.0.weight torch.Size([256, 512])\n",
      "linear512to256.0.bias torch.Size([256])\n",
      "linear512to256.1.weight torch.Size([256])\n",
      "linear512to256.1.bias torch.Size([256])\n",
      "linear512to256.1.running_mean torch.Size([256])\n",
      "linear512to256.1.running_var torch.Size([256])\n",
      "linear512to256.1.num_batches_tracked torch.Size([])\n",
      "linear256to256.0.weight torch.Size([256, 256])\n",
      "linear256to256.0.bias torch.Size([256])\n",
      "linear256to256.1.weight torch.Size([256])\n",
      "linear256to256.1.bias torch.Size([256])\n",
      "linear256to256.1.running_mean torch.Size([256])\n",
      "linear256to256.1.running_var torch.Size([256])\n",
      "linear256to256.1.num_batches_tracked torch.Size([])\n",
      "linear256to128.0.weight torch.Size([128, 256])\n",
      "linear256to128.0.bias torch.Size([128])\n",
      "linear256to128.1.weight torch.Size([128])\n",
      "linear256to128.1.bias torch.Size([128])\n",
      "linear256to128.1.running_mean torch.Size([128])\n",
      "linear256to128.1.running_var torch.Size([128])\n",
      "linear256to128.1.num_batches_tracked torch.Size([])\n",
      "linear128to128.0.weight torch.Size([128, 128])\n",
      "linear128to128.0.bias torch.Size([128])\n",
      "linear128to128.1.weight torch.Size([128])\n",
      "linear128to128.1.bias torch.Size([128])\n",
      "linear128to128.1.running_mean torch.Size([128])\n",
      "linear128to128.1.running_var torch.Size([128])\n",
      "linear128to128.1.num_batches_tracked torch.Size([])\n",
      "linear128to64.0.weight torch.Size([64, 128])\n",
      "linear128to64.0.bias torch.Size([64])\n",
      "linear128to64.1.weight torch.Size([64])\n",
      "linear128to64.1.bias torch.Size([64])\n",
      "linear128to64.1.running_mean torch.Size([64])\n",
      "linear128to64.1.running_var torch.Size([64])\n",
      "linear128to64.1.num_batches_tracked torch.Size([])\n",
      "linear64to64.0.weight torch.Size([64, 64])\n",
      "linear64to64.0.bias torch.Size([64])\n",
      "linear64to64.1.weight torch.Size([64])\n",
      "linear64to64.1.bias torch.Size([64])\n",
      "linear64to64.1.running_mean torch.Size([64])\n",
      "linear64to64.1.running_var torch.Size([64])\n",
      "linear64to64.1.num_batches_tracked torch.Size([])\n",
      "linear64to32.0.weight torch.Size([32, 64])\n",
      "linear64to32.0.bias torch.Size([32])\n",
      "linear64to32.1.weight torch.Size([32])\n",
      "linear64to32.1.bias torch.Size([32])\n",
      "linear64to32.1.running_mean torch.Size([32])\n",
      "linear64to32.1.running_var torch.Size([32])\n",
      "linear64to32.1.num_batches_tracked torch.Size([])\n",
      "linear32to32.0.weight torch.Size([32, 32])\n",
      "linear32to32.0.bias torch.Size([32])\n",
      "linear32to32.1.weight torch.Size([32])\n",
      "linear32to32.1.bias torch.Size([32])\n",
      "linear32to32.1.running_mean torch.Size([32])\n",
      "linear32to32.1.running_var torch.Size([32])\n",
      "linear32to32.1.num_batches_tracked torch.Size([])\n",
      "linear32to1.weight torch.Size([1, 32])\n",
      "linear32to1.bias torch.Size([1])\n",
      "projectionXto1024.weight torch.Size([1024, 49])\n",
      "projectionXto1024.bias torch.Size([1024])\n",
      "projection1024to512.weight torch.Size([512, 1024])\n",
      "projection1024to512.bias torch.Size([512])\n",
      "projection512to256.weight torch.Size([256, 512])\n",
      "projection512to256.bias torch.Size([256])\n",
      "projection256to128.weight torch.Size([128, 256])\n",
      "projection256to128.bias torch.Size([128])\n",
      "projection128to64.weight torch.Size([64, 128])\n",
      "projection128to64.bias torch.Size([64])\n",
      "projection64to32.weight torch.Size([32, 64])\n",
      "projection64to32.bias torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for name, param in irnet.state_dict().items():\n",
    "    print(name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1128,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "#criterion = nn.L1Loss()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(irnet.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 5545.9810\n",
      "Epoch [2/100], Loss: 5545.0425\n",
      "Epoch [3/100], Loss: 5527.0493\n",
      "Epoch [4/100], Loss: 5554.5806\n",
      "Epoch [5/100], Loss: 5891.8247\n",
      "Epoch [6/100], Loss: 5847.9971\n",
      "Epoch [7/100], Loss: 5494.1157\n",
      "Epoch [8/100], Loss: 5946.0024\n",
      "Epoch [9/100], Loss: 5491.0562\n",
      "Epoch [10/100], Loss: 5946.6216\n",
      "Epoch [11/100], Loss: 5504.5732\n",
      "Epoch [12/100], Loss: 5868.8447\n",
      "Epoch [13/100], Loss: 5470.9624\n",
      "Epoch [14/100], Loss: 5810.6680\n",
      "Epoch [15/100], Loss: 5438.3301\n",
      "Epoch [16/100], Loss: 5686.2690\n",
      "Epoch [17/100], Loss: 5439.0933\n",
      "Epoch [18/100], Loss: 5597.0107\n",
      "Epoch [19/100], Loss: 5463.2705\n",
      "Epoch [20/100], Loss: 5511.4683\n",
      "Epoch [21/100], Loss: 5455.0884\n",
      "Epoch [22/100], Loss: 5456.6538\n",
      "Epoch [23/100], Loss: 5427.4375\n",
      "Epoch [24/100], Loss: 5387.4780\n",
      "Epoch [25/100], Loss: 5395.9009\n",
      "Epoch [26/100], Loss: 5332.3120\n",
      "Epoch [27/100], Loss: 5309.3013\n",
      "Epoch [28/100], Loss: 5246.7744\n",
      "Epoch [29/100], Loss: 5224.4131\n",
      "Epoch [30/100], Loss: 5168.0723\n",
      "Epoch [31/100], Loss: 5084.4375\n",
      "Epoch [32/100], Loss: 5050.8389\n",
      "Epoch [33/100], Loss: 4908.7207\n",
      "Epoch [34/100], Loss: 4849.0054\n",
      "Epoch [35/100], Loss: 4714.9468\n",
      "Epoch [36/100], Loss: 4485.8418\n",
      "Epoch [37/100], Loss: 4329.4565\n",
      "Epoch [38/100], Loss: 4222.2480\n",
      "Epoch [39/100], Loss: 4169.6870\n",
      "Epoch [40/100], Loss: 4249.7988\n",
      "Epoch [41/100], Loss: 4166.4370\n",
      "Epoch [42/100], Loss: 3317.5862\n",
      "Epoch [43/100], Loss: 2514.7920\n",
      "Epoch [44/100], Loss: 2447.5403\n",
      "Epoch [45/100], Loss: 3138.9341\n",
      "Epoch [46/100], Loss: 4693.5645\n",
      "Epoch [47/100], Loss: 3773.8469\n",
      "Epoch [48/100], Loss: 1723.7659\n",
      "Epoch [49/100], Loss: 3115.9873\n",
      "Epoch [50/100], Loss: 1895.6830\n",
      "Epoch [51/100], Loss: 2241.1614\n",
      "Epoch [52/100], Loss: 1804.1125\n",
      "Epoch [53/100], Loss: 1884.9572\n",
      "Epoch [54/100], Loss: 1547.7963\n",
      "Epoch [55/100], Loss: 1633.7876\n",
      "Epoch [56/100], Loss: 1307.4664\n",
      "Epoch [57/100], Loss: 1416.1737\n",
      "Epoch [58/100], Loss: 1077.8798\n",
      "Epoch [59/100], Loss: 1220.4987\n",
      "Epoch [60/100], Loss: 885.5019\n",
      "Epoch [61/100], Loss: 1017.0336\n",
      "Epoch [62/100], Loss: 727.7175\n",
      "Epoch [63/100], Loss: 700.9586\n",
      "Epoch [64/100], Loss: 634.1376\n",
      "Epoch [65/100], Loss: 455.3244\n",
      "Epoch [66/100], Loss: 467.8834\n",
      "Epoch [67/100], Loss: 332.0202\n",
      "Epoch [68/100], Loss: 261.6324\n",
      "Epoch [69/100], Loss: 279.5664\n",
      "Epoch [70/100], Loss: 217.5527\n",
      "Epoch [71/100], Loss: 139.5395\n",
      "Epoch [72/100], Loss: 161.9825\n",
      "Epoch [73/100], Loss: 141.2713\n",
      "Epoch [74/100], Loss: 85.6193\n",
      "Epoch [75/100], Loss: 97.3877\n",
      "Epoch [76/100], Loss: 123.2292\n",
      "Epoch [77/100], Loss: 92.0885\n",
      "Epoch [78/100], Loss: 61.9323\n",
      "Epoch [79/100], Loss: 74.1210\n",
      "Epoch [80/100], Loss: 85.0938\n",
      "Epoch [81/100], Loss: 62.8888\n",
      "Epoch [82/100], Loss: 47.0515\n",
      "Epoch [83/100], Loss: 49.6599\n",
      "Epoch [84/100], Loss: 50.8615\n",
      "Epoch [85/100], Loss: 41.8153\n",
      "Epoch [86/100], Loss: 31.3700\n",
      "Epoch [87/100], Loss: 33.6728\n",
      "Epoch [88/100], Loss: 41.1037\n",
      "Epoch [89/100], Loss: 35.0429\n",
      "Epoch [90/100], Loss: 21.4733\n",
      "Epoch [91/100], Loss: 21.4193\n",
      "Epoch [92/100], Loss: 26.7061\n",
      "Epoch [93/100], Loss: 23.3819\n",
      "Epoch [94/100], Loss: 16.6941\n",
      "Epoch [95/100], Loss: 19.8226\n",
      "Epoch [96/100], Loss: 23.2266\n",
      "Epoch [97/100], Loss: 18.3101\n",
      "Epoch [98/100], Loss: 16.0910\n",
      "Epoch [99/100], Loss: 19.6516\n",
      "Epoch [100/100], Loss: 19.4519\n"
     ]
    }
   ],
   "source": [
    "losses_train = []\n",
    "losses_val = []\n",
    "epochs = []\n",
    "minLoss = 100.0\n",
    "minOutput = torch.Tensor(X_train.shape[0], 1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = irnet(X_train.float())\n",
    "    val_outputs = irnet(X_val.float())\n",
    "    #print(type(outputs), outputs.shape)\n",
    "    #print(outputs)\n",
    "    #print(final_output)\n",
    "    #print(outputs.shape)\n",
    "    #print(ytor.shape)\n",
    "    loss = criterion(outputs, y_train.float())\n",
    "    if loss.data < minLoss:\n",
    "        minLoss = loss.data\n",
    "        minOutput = outputs\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch [%d/%d], Loss: %.4f'\n",
    "         %(epoch+1, num_epochs, loss.data))\n",
    "    epochs.append(epoch)\n",
    "    losses_train.append(loss)\n",
    "    losses_val.append(criterion(val_outputs, y_val.float()))\n",
    "#print(minLoss.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(losses_train)):\n",
    "    losses_train[i] = losses_train[i].cpu().detach().numpy()\n",
    "    losses_val[i] = losses_val[i].cpu().detach().numpy()\n",
    "#     losses_train[i] = losses_train[i]\n",
    "#     losses_val[i] = losses_val[i]\n",
    "plt.plot(epochs, losses_train)\n",
    "plt.plot(epochs, losses_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1131,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output_train = irnet(X_train.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on training set using 17 layer IRNet after 100 iterations:\n",
      "------------------------------\n",
      "r2 score:  0.996717960030913\n",
      "Mean Absolute Error: 15.417576\n",
      "Mean Squared Error:  15.417574895705613\n",
      "Root mean squared error:  3.926521984620182\n"
     ]
    }
   ],
   "source": [
    "print('Results on training set using 17 layer IRNet after %d iterations:\\n------------------------------'%(num_epochs))\n",
    "print('r2 score: ', r2_score(y_train.cpu().detach().numpy(), final_output_train.cpu().detach().numpy()))\n",
    "print('Mean Absolute Error:', criterion(final_output_train, y_train.float()).cpu().detach().numpy())\n",
    "print('Mean Squared Error: ', mean_squared_error(y_train.cpu().detach().numpy(), final_output_train.cpu().detach().numpy()))\n",
    "print('Root mean squared error: ', np.sqrt(mean_squared_error(y_train.cpu().detach().numpy(), final_output_train.cpu().detach().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1133,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output_test = irnet(X_test.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on test set using 17 layer IRNet after 100 iterations:\n",
      "------------------------------\n",
      "Mean Absolute Error: 296.6737\n",
      "r2 score:  0.9589243353465142\n",
      "Mean Squared Error:  296.6737405343737\n",
      "Root mean squared error:  17.224219591446623\n"
     ]
    }
   ],
   "source": [
    "print('Results on test set using 17 layer IRNet after %d iterations:\\n------------------------------'%(num_epochs))\n",
    "print('Mean Absolute Error:', criterion(final_output_test, y_test.float()).cpu().detach().numpy())\n",
    "print('r2 score: ', r2_score(y_test.cpu().detach().numpy(), final_output_test.cpu().detach().numpy()))\n",
    "print('Mean Squared Error: ', mean_squared_error(y_test.cpu().detach().numpy(), final_output_test.cpu().detach().numpy()))\n",
    "print('Root mean squared error: ', np.sqrt(mean_squared_error(y_test.cpu().detach().numpy(), final_output_test.cpu().detach().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------using random forest--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=200, random_state=5)\n",
    "regressor.fit(X_train.cpu().detach().numpy(), y_train.view(y_train.shape[0]).cpu().detach().numpy())\n",
    "predictions_train = regressor.predict(X_train.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on training set using Random Forest\n",
      "------------------\n",
      "r2 score:  0.9807922642494815\n",
      "Mean Absolute Error: 40.96215\n",
      "Mean Squared Error:  90.22946316918666\n",
      "Root Mean Squared Error:  9.498919052670502\n"
     ]
    }
   ],
   "source": [
    "errors = abs(predictions_train - y_train.cpu().detach().numpy())\n",
    "mse = mean_squared_error(y_train.cpu().detach().numpy(), predictions_train)\n",
    "\n",
    "print('Results on training set using Random Forest\\n------------------')\n",
    "print('r2 score: ', r2_score(y_train.cpu().detach().numpy(), predictions_train))\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 5))\n",
    "print('Mean Squared Error: ', mse)\n",
    "print('Root Mean Squared Error: ', np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1098,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = regressor.predict(X_test.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on test set using Random Forest\n",
      "------------------\n",
      "r2 score:  0.9440027530847319\n",
      "Mean Absolute Error: 55.27356\n",
      "Mean Squared Error:  404.44659489081863\n",
      "Root Mean Squared Error:  20.110857636879107\n"
     ]
    }
   ],
   "source": [
    "errors = abs(predictions_test - y_test.cpu().detach().numpy())\n",
    "mse = mean_squared_error(y_test.cpu().detach().numpy(), predictions_test)\n",
    "\n",
    "print('Results on test set using Random Forest\\n------------------')\n",
    "print('r2 score: ', r2_score(y_test.cpu().detach().numpy(), predictions_test))\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 5))\n",
    "print('Mean Squared Error: ', mse)\n",
    "print('Root Mean Squared Error: ', np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- with batch gradient descent ----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pm = df['Piezoelectric_Modulus'].values\n",
    "# excluded = [\"Materials\", \"Piezoelectric_Modulus\", \"mp_id\", \n",
    "#             \"composition\", \"Crystal_Symmetry\", \"composition_oxid\"]\n",
    "# dset = df.drop(excluded, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dset.values, dset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dset = torch.from_numpy(dset.values)\n",
    "# pm = torch.from_numpy(pm)\n",
    "# dataset = Data.TensorDataset(dset, pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set, test_set = torch.utils.data.random_split(dataset, [1536, 169])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = Data.DataLoader(dataset=train_set, batch_size=32, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses = []\n",
    "# epochs = []\n",
    "# for epoch in range(num_epochs):\n",
    "#     for i, (batch_X, batch_y) in enumerate(train_loader):\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         Xtor = Variable(batch_X).to(device)\n",
    "#         ytor = Variable(batch_y.view(32, 1)).to(device)\n",
    "        \n",
    "#         outputs = irnet(Xtor.float())\n",
    "#         #print(outputs.shape)\n",
    "#         #print(ytor.shape)\n",
    "#         loss = criterion(outputs, ytor.float())\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     print('Epoch [%d/%d], Loss: %.4f'\n",
    "#          %(epoch+1, num_epochs, loss.data))\n",
    "#     epochs.append(epoch)\n",
    "#     losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
